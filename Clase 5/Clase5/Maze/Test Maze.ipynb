{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/MattChanTK/gym-maze\n",
    "# !pip install gym pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mazeEnvExtended import MazeEnvExtended\n",
    "from agent import Agent\n",
    "from modelExample import ModelExample\n",
    "from modelLRTA import ModelLRTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze_name = \"MazeEnv10x10_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MazeEnvExtended(maze_file = maze_name + '.npy', mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.action_space.start, env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 9.0, (2,), float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [ 20, 159,  20],\n",
       "        [ 20, 159,  20],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [ 20, 159,  20],\n",
       "        [ 20, 159,  20],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hago Nada\n"
     ]
    }
   ],
   "source": [
    "model = ModelLRTA(model_file = maze_name + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modelLRTA.ModelLRTA object at 0x0000019AC02C0EB0>\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play manually...\n",
      "Goal 0 is (99, True)\n",
      "obs=[0 0] reward=0 done_env=False\n",
      "Goal 1 is (99, True)\n",
      "obs=[0 0] reward=0 done_env=False\n",
      "Goal 2 is (99, True)\n",
      "obs=[0 1] reward=0 done_env=False\n",
      "Goal 3 is (99, True)\n",
      "obs=[0 1] reward=0 done_env=False\n",
      "Goal 4 is (99, True)\n",
      "obs=[0 1] reward=0 done_env=False\n",
      "Goal 5 is (99, True)\n",
      "obs=[0 2] reward=0 done_env=False\n",
      "Goal 6 is (99, True)\n",
      "obs=[0 2] reward=0 done_env=False\n",
      "Goal 7 is (99, True)\n",
      "obs=[0 2] reward=0 done_env=False\n",
      "Goal 8 is (99, True)\n",
      "obs=[0 3] reward=0 done_env=False\n",
      "Goal 9 is (99, True)\n",
      "obs=[0 3] reward=0 done_env=False\n",
      "Goal 10 is (99, True)\n",
      "obs=[0 3] reward=0 done_env=False\n",
      "Goal 11 is (99, True)\n",
      "obs=[0 4] reward=0 done_env=False\n",
      "Goal 12 is (99, True)\n",
      "obs=[0 4] reward=0 done_env=False\n",
      "Goal 13 is (99, True)\n",
      "obs=[0 4] reward=0 done_env=False\n",
      "Goal 14 is (99, True)\n",
      "obs=[0 5] reward=0 done_env=False\n",
      "Goal 15 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 16 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 17 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 18 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 19 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 20 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 21 is (99, True)\n",
      "obs=[2 4] reward=0 done_env=False\n",
      "Goal 22 is (99, True)\n",
      "obs=[2 4] reward=0 done_env=False\n",
      "Goal 23 is (99, True)\n",
      "obs=[2 4] reward=0 done_env=False\n",
      "Goal 24 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 25 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 26 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 27 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 28 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 29 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 30 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 31 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 32 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 33 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 34 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 35 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 36 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 37 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 38 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 39 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 40 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 41 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 42 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 43 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 44 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n",
      "Goal 45 is (99, True)\n",
      "obs=[1 5] reward=0 done_env=False\n",
      "Goal 46 is (99, True)\n",
      "obs=[2 5] reward=0 done_env=False\n"
     ]
    }
   ],
   "source": [
    "rewards, step_counter = agent.run(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, step_counter"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a12ff8c7a91ea37f5992d09ea518b599018c1dcd85b39a87bb2da8ef6d0f94da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
